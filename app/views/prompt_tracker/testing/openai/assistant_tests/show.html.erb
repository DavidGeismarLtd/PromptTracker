<% content_for :breadcrumbs do %>
  <li class="breadcrumb-item"><%= link_to "OpenAI Assistants", testing_openai_assistants_path %></li>
  <li class="breadcrumb-item"><%= link_to @assistant.name, testing_openai_assistant_path(@assistant) %></li>
  <li class="breadcrumb-item active"><%= @test.name %></li>
<% end %>

<%# Subscribe to Turbo Stream updates for this test %>
<%= turbo_stream_from "test_#{@test.id}" %>

<div class="row mb-4">
  <div class="col">
    <h1>
      <i class="bi bi-check2-square"></i> <%= @test.name %>
      <% unless @test.enabled? %>
        <span class="badge bg-secondary">Disabled</span>
      <% end %>
    </h1>
    <p class="text-muted"><%= @test.description %></p>
  </div>
  <div class="col-auto d-flex gap-2">
    <%= link_to edit_testing_openai_assistant_test_path(@assistant, @test), class: "btn btn-outline-secondary" do %>
      <i class="bi bi-pencil"></i> Edit
    <% end %>
    <button type="button" class="btn btn-success" data-bs-toggle="modal" data-bs-target="#runTestModal">
      <i class="bi bi-play-circle"></i> Run Test
    </button>
  </div>
</div>

<!-- Run Test Modal -->
<div class="modal fade" id="runTestModal" tabindex="-1">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Run Test</h5>
        <button type="button" class="btn-close" data-bs-dismiss="modal"></button>
      </div>
      <%= form_with url: run_testing_openai_assistant_test_path(@assistant, @test), method: :post do |f| %>
        <div class="modal-body">
          <div class="mb-3">
            <%= f.label :run_mode, "Run Mode", class: "form-label" %>
            <%= f.select :run_mode, [["Dataset", "dataset"], ["Custom Scenario", "custom"]], {}, class: "form-select", id: "runModeSelect" %>
          </div>

          <div id="datasetMode">
            <div class="mb-3">
              <%= f.label :dataset_id, "Select Dataset", class: "form-label" %>
              <%= f.select :dataset_id, @assistant.datasets.map { |d| [d.name, d.id] }, { include_blank: "Select a dataset..." }, class: "form-select" %>
            </div>
          </div>

          <div id="customMode" style="display: none;">
            <div class="mb-3">
              <%= f.label :user_prompt, "User Prompt", class: "form-label" %>
              <%= f.text_area :user_prompt, class: "form-control", rows: 3, placeholder: "Enter the prompt that will be used to simulate the user's conversation with the assistant..." %>
              <div class="form-text">This is the prompt that will be used to simulate the user's conversation with the assistant. Each message from the simulated user will be generated by an LLM based on this prompt.</div>
            </div>
            <div class="mb-3">
              <%= f.label :max_turns, "Max Turns", class: "form-label" %>
              <%= f.number_field :max_turns, class: "form-control", value: 3, min: 1, max: 20 %>
              <div class="form-text">Maximum number of conversation turns (1-20)</div>
            </div>
          </div>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Cancel</button>
          <%= f.submit "Run Test", class: "btn btn-success" %>
        </div>
      <% end %>
    </div>
  </div>
</div>

<script>
  document.getElementById('runModeSelect')?.addEventListener('change', function() {
    const datasetMode = document.getElementById('datasetMode');
    const customMode = document.getElementById('customMode');
    if (this.value === 'dataset') {
      datasetMode.style.display = 'block';
      customMode.style.display = 'none';
    } else {
      datasetMode.style.display = 'none';
      customMode.style.display = 'block';
    }
  });
</script>

<!-- Test Stats -->
<div class="row mb-4">
  <div class="col-md-3">
    <div class="card metric-card">
      <div class="metric-value">
        <% if @test.passing? %>
          <span class="text-success">✓ Passing</span>
        <% elsif @test.test_runs.any? %>
          <span class="text-danger">✗ Failing</span>
        <% else %>
          <span class="text-muted">No Runs</span>
        <% end %>
      </div>
      <div class="metric-label">Status</div>
    </div>
  </div>
  <div class="col-md-3">
    <div class="card metric-card">
      <div class="metric-value"><%= number_to_percentage(@test.pass_rate, precision: 0) %></div>
      <div class="metric-label">Pass Rate</div>
    </div>
  </div>
  <div class="col-md-3">
    <div class="card metric-card">
      <div class="metric-value"><%= @test.test_runs.count %></div>
      <div class="metric-label">Total Runs</div>
    </div>
  </div>
  <div class="col-md-3">
    <div class="card metric-card">
      <div class="metric-value">
        <% if @test.last_run_avg_score.present? %>
          <%= @test.last_run_avg_score.round(0) %>
        <% else %>
          N/A
        <% end %>
      </div>
      <div class="metric-label">Avg Score (Last Run)</div>
    </div>
  </div>
</div>

<!-- Evaluators -->
<div class="card mb-4">
  <div class="card-header">
    <h5 class="mb-0">Evaluators</h5>
  </div>
  <div class="card-body">
    <% if @test.evaluator_configs.any? %>
      <% @test.evaluator_configs.each do |config| %>
        <div class="mb-3 p-3 border rounded">
          <h6><%= config.evaluator_type.demodulize %></h6>
          <pre class="bg-light p-2 rounded mb-0"><code><%= JSON.pretty_generate(config.config) %></code></pre>
        </div>
      <% end %>
    <% else %>
      <p class="text-muted mb-0">No evaluators configured.</p>
    <% end %>
  </div>
</div>

<!-- Recent Test Runs -->
<div class="card">
  <div class="card-header">
    <h5 class="mb-0">Recent Test Runs</h5>
  </div>
  <div class="card-body">
    <% if @recent_runs.any? %>
      <div class="table-responsive">
        <table class="table table-hover">
          <thead>
            <tr>
              <th>Run Time</th>
              <th>Status</th>
              <th>Score</th>
              <th>Dataset</th>
              <th>Actions</th>
            </tr>
          </thead>
          <tbody>
            <% @recent_runs.each do |run| %>
              <tr>
                <td><%= time_ago_in_words(run.created_at) %> ago</td>
                <td>
                  <% case run.status %>
                  <% when "passed" %>
                    <span class="badge bg-success">Passed</span>
                  <% when "failed" %>
                    <span class="badge bg-danger">Failed</span>
                  <% when "running" %>
                    <span class="badge bg-primary">Running</span>
                  <% when "error" %>
                    <span class="badge bg-warning">Error</span>
                  <% else %>
                    <span class="badge bg-secondary"><%= run.status.titleize %></span>
                  <% end %>
                </td>
                <td>
                  <% if run.evaluations.any? %>
                    <%= run.evaluations.average(:score).round(1) %>%
                  <% else %>
                    N/A
                  <% end %>
                </td>
                <td>
                  <% if run.dataset %>
                    <%= run.dataset.name %>
                  <% else %>
                    <span class="text-muted">Custom</span>
                  <% end %>
                </td>
                <td>
                  <%= link_to "View", testing_run_path(run), class: "btn btn-sm btn-outline-primary" %>
                </td>
              </tr>
            <% end %>
          </tbody>
        </table>
      </div>
    <% else %>
      <p class="text-muted mb-0">No test runs yet. Click "Run Test" to start.</p>
    <% end %>
  </div>
</div>
