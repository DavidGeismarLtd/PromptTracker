# frozen_string_literal: true

# == Schema Information
#
# Table name: prompt_tracker_dataset_rows
#
#  created_at :datetime         not null
#  dataset_id :bigint           not null
#  id         :bigint           not null, primary key
#  metadata   :jsonb            not null
#  row_data   :jsonb            not null
#  source     :string           default("manual"), not null
#  updated_at :datetime         not null
#
module PromptTracker
  # Represents a single row of test data within a dataset.
  #
  # Each row contains variable values that match the dataset's schema.
  # Rows can be created manually, generated by LLMs, or imported from external sources.
  #
  # @example Create a manual row
  #   row = dataset.dataset_rows.create!(
  #     row_data: { customer_name: "Alice", issue: "billing" },
  #     source: "manual"
  #   )
  #
  # @example Create an LLM-generated row
  #   row = dataset.dataset_rows.create!(
  #     row_data: { customer_name: "Bob", issue: "refund" },
  #     source: "llm_generated",
  #     metadata: { generation_prompt: "Create edge case scenarios" }
  #   )
  #
  class DatasetRow < ApplicationRecord
    # Constants
    SOURCES = %w[manual llm_generated imported].freeze

    # Reserved fields that can exist in row_data but are not part of the dataset schema
    # These fields have special purposes and should not be validated against the schema
    RESERVED_FIELDS = %w[mock_function_outputs].freeze

    # Associations
    belongs_to :dataset,
               class_name: "PromptTracker::Dataset",
               inverse_of: :dataset_rows

    has_many :test_runs,
             class_name: "PromptTracker::TestRun",
             dependent: :nullify,
             inverse_of: :dataset_row

    # Delegate to get prompt_version through dataset
    has_one :prompt_version, through: :dataset

    # Validations
    validates :row_data, presence: true
    validates :source, presence: true, inclusion: { in: SOURCES }

    validate :row_data_must_be_hash
    validate :row_data_matches_schema

    # Scopes
    scope :recent, -> { order(created_at: :desc) }
    scope :manual, -> { where(source: "manual") }
    scope :llm_generated, -> { where(source: "llm_generated") }
    scope :imported, -> { where(source: "imported") }

    # Callbacks
    after_create_commit :broadcast_prepend_to_dataset
    after_update_commit :broadcast_replace_to_dataset
    after_destroy_commit :broadcast_remove_to_dataset

    # Get variable value
    #
    # @param variable_name [String, Symbol] the variable name
    # @return [Object] the variable value
    def get_variable(variable_name)
      row_data[variable_name.to_s]
    end

    # Set variable value
    #
    # @param variable_name [String, Symbol] the variable name
    # @param value [Object] the variable value
    def set_variable(variable_name, value)
      self.row_data = row_data.merge(variable_name.to_s => value)
    end

    private

    # Broadcast prepend to dataset rows table
    # Uses prepend to show newest rows first (most recent at top)
    def broadcast_prepend_to_dataset
      partial_path, locals = row_partial_and_locals

      broadcast_prepend_to(
        "dataset_#{dataset_id}_rows",
        target: "dataset-rows",
        partial: partial_path,
        locals: locals
      )

      # Update row count
      broadcast_update_to(
        "dataset_#{dataset_id}_rows",
        target: "dataset-row-count",
        html: dataset.dataset_rows.count.to_s
      )

      # Remove empty state if this is the first row
      if dataset.dataset_rows.count == 1
        broadcast_remove_to(
          "dataset_#{dataset_id}_rows",
          target: "empty-state"
        )
      end
    end

    # Broadcast replace to dataset rows table
    # Skip modal rendering to avoid duplicates (modal stays in DOM, only row content updates)
    def broadcast_replace_to_dataset
      partial_path, locals = row_partial_and_locals

      broadcast_replace_to(
        "dataset_#{dataset_id}_rows",
        target: "dataset-row-#{id}",
        partial: partial_path,
        locals: locals.merge(skip_modal: true)
      )
    end

    # Broadcast remove from dataset rows table
    def broadcast_remove_to_dataset
      broadcast_remove_to(
        "dataset_#{dataset_id}_rows",
        target: "dataset-row-#{id}"
      )

      # Update row count
      broadcast_update_to(
        "dataset_#{dataset_id}_rows",
        target: "dataset-row-count",
        html: dataset.dataset_rows.count.to_s
      )

      # Remove the edit modal for this row
      broadcast_remove_to(
        "dataset_#{dataset_id}_rows",
        target: "editRowModal-#{id}"
      )
    end

    # Get the correct partial path and locals for Turbo Stream broadcasts
    # All testable types now use the same unified partial
    def row_partial_and_locals
      index = dataset.dataset_rows.where("id <= ?", id).count
      [
        "prompt_tracker/testing/datasets/row",
        { row: self, index: index, dataset: dataset }
      ]
    end

    # Validate that row_data is a hash
    def row_data_must_be_hash
      return if row_data.nil? || row_data.is_a?(Hash)

      errors.add(:row_data, "must be a hash")
    end

    # Validate that row_data matches dataset schema
    def row_data_matches_schema
      return if dataset.blank? || dataset.schema.blank?
      return unless row_data.is_a?(Hash) # Skip if row_data is not a hash (handled by row_data_must_be_hash)

      schema_variable_names = dataset.variable_names
      row_variable_names = row_data.keys

      # Check for missing required variables
      required_vars = dataset.schema.select { |v| v["required"] == true }.map { |v| v["name"] }
      missing_vars = required_vars - row_variable_names

      if missing_vars.any?
        errors.add(:row_data, "missing required variables: #{missing_vars.join(', ')}")
      end

      # Check for extra variables not in schema (excluding reserved fields)
      # Reserved fields like mock_function_outputs have special purposes and don't need to be in the schema
      extra_vars = row_variable_names - schema_variable_names - RESERVED_FIELDS

      if extra_vars.any?
        errors.add(:row_data, "contains unknown variables: #{extra_vars.join(', ')}")
      end
    end
  end
end
